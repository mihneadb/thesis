% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 1. \emph{Introduction}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------

Many-Task Computing (MTC)\cite{mtc} is a new computing paradigm that attempts to place itself in-between High-Throughput Computing (HTC) and High-Performance Computing (HPC). The core idea of MTC is that it uses large amounts of computing resources over short periods of time, in order to complete multiple tasks. While a common metric in HTC is the number of tasks fulfilled per month, MTC is usually quantified in tasks per second. Also, as opposed to other paradigms that use message passing as a way to communicate between successive steps in a computation, MTC couples its compute phases via files. Because of this, another common metric of MTC is megabytes per second (MB/s).

Any computing task that is comprised of multiple small parallel jobs is a good fit for MTC. Multiple applications have been found good fits for MTC\cite{mtc}, spanning domains like astronomy, astrophysics, economic modelling, pharmaceutics, chemistry, bioinformatics, neuroscience, data analytics, data mining and biometrics.

MTC exhibits a specific set of technical particularities which need to be properly supported in order to obtain good performance. The high number of parallel tasks that need to be executed underlines the importance of a streamlined scheduling system. Besides that, the way the tasks use files to communicate makes the overall performance largely dependant on the underlying filesystem performance. For the purpose of our subject, we will focus on the filesystem aspect.

% TODO <diagram with tasks using files storing data and then new tasks using that data>

Typically, MTC jobs are run on clusters of compute nodes. These compute nodes need to share data files between them in order to complete the tasks that are assigned to them. Usually, files are locally stored on disk drives (either mechanical disk drives or solid state drives), and get sent over the network when a different node needs access. However, even with the fastest drives commercially available today, the transfer rates of disk drives are inferior to the bandwidth of InfiniBand connections that are used in clusters, considering the fact that a SATA link tops out at 3 GBps while InfiniBand 12X supports a 30 GBps data link. This shows that the bottleneck is not the network, but the storage technology. To overcome this bottleneck, RAM can be used as a storage medium. Obviously it cannot achieve the same storage capacity as regular disk drives, but that is not a problem for the purposes of MTC, as the data files used are not so large in size.

In order to make use of the high speed RAM and network connections that compute nodes in today's clusters have, research groups have started work on developing distributed, in-memory filesystems. These filesystems are specifically designed to support MTC workloads and yield better results than common network filesystems like NFS.

% TODO <diagram showing that amfs/memfs is better than nfs>

To illustrate how such filesystems work, we will describe two implementations - AMFS\cite{amfs} and MemFS\cite{memfs}.

** memfs
** amfs

% TODO - discuss the two filesystems


Besides the different storage medium (RAM), MTC-specific filesystems also target different access patterns. First, there is the usual 1-to-1 read pattern, where a node needs access to one file. In MTC workloads, it's probable that the file will reside on a different node's local storage. Second, there is the more complicated N-to-1 read pattern, where multiple nodes need to access the exact same file that is stored on a single node's local storage. In order for the MTC workload to achieve maximum performance, the underlying filesystem should make the most out of the network bandwidth, without creating bottlenecks because of contention.

In order to properly benchmark these filesystems, we need a tool that can simulate the MTC specific access patterns. This tool should be able to support a variable number of nodes, such that the scalability of the filesystem can be measured. Furthermore, the benchmark should be able to coordinate the nodes in a deterministic and synchronized manner in order to correctly reproduce access patterns such as N-to-1 reads. Finally, the results aggregation step should be built in, to facilitate tracking performance improvements between different test runs. Our solution provides all these features and, in addition, it uses a simple JSON file to specify complex test cases. We will detail all features later, in this study.


The rest of this study is structured as follows: Chapter 2 provides more context on benchmarking distributed MTC filesystems and related work. In Chapter 3 we discuss our implementation, as well as the design decisions we have made. Then, in Chapter 4 we evaluate the performance of our solution. Finally, Chapter 5 presents our conclusions.